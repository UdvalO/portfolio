{
  "hash": "4da5e3b24f583543d4fe83858e03fb2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Certification Exam\"\ndate: \"2024-06-23\"\ncategories: [R, SQL, analysis]\nimage: \"certificate.jpg\"\n---\n\n\n\n## Certified Data Analyst Exam Submission\n\nAs part of the certified data analyst exam by DataCamp, I completed a two-hour exam testing my R and SQL skills, followed by a four-hour practical exam where I analyzed sales data from a stationary shop.\n\nThe goal of the analysis was to determine the best-performing marketing method following the launch of new products. Additionally, I identified high-paying and loyal customers to prioritize them in the marketing strategy for future product launches. Here are some examples but the full report can be found [here](https://www.datacamp.com/datalab/w/efdedffd-1df1-4b55-be0e-4c7c6ed91eb7).\n\nAnalysis was conduct with following components:\n\n1.  **Data Cleaning and Validation:** first I conducted a validation and cleaning, including correcting categorical inconsistencies, handling missing values, range validation, and ensuring data type consistency.\n\n2.  **Exploratory Analysis:** here I focused on comprehending the performance of the sales methods over time, specifically examining their impact on sales volume across different states. Additionally, I also analyzed whether loyal customers or new customers showed more interest in the new product offerings.\n\n3.  **Key Business Metric Identification:** the key business metric the company continue utilize is sales over time attributed to each method and the comparison of sales in loyal and occasional customers after a product launch.\n\n4.  **Recommendation:**\n\n    -   The revenue experienced exponential growth during the first six weeks. Therefore, continuous monitoring of different sales methods over time is essential to assess their ongoing performance.\n\n    -   It is evident that the \"Call\" method generates the least revenue despite requiring the most employee time. Therefore, it is recommended to significantly reduce the use of this method and focus more on the \"Email + Call\" and \"Email\" methods.\n\n    -   Newer customers tend to purchase more new products, indicating that a marketing plan targeting new customers would be highly beneficial.\n\n    -   High-paying customers (fewer than 500 in total) should be incentivized. Additionally, marketing efforts should target these customers based on their locations to maximize effectiveness.\n\n5.  **Presentation**: Then the findings were presented through a 12 minute recorded video.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nsetwd(\"C:/Users/udwal/Documents/Studies_Viadrina/Becoming Data Fluent/Fluent2024/Bonus Assignment/Portfolio\")\n\n# Importing data\ndata <- read_csv(\"product_sales.csv\")\n\n#  Checking uneque customer IDs\nnum_unique_customers <- length(unique(data$customer_id))\n\n# Checking column unique categorical values \nunique_methods <- unique(data$sales_method)\n\n# fixing typos\ntypo_dict <- c(\n  \"em + call\" = \"Email + Call\",\n  \"email\" = \"Email\")\n\ndata <- data %>%\n  mutate(sales_method = coalesce(typo_dict[sales_method], sales_method))\n\n# Cehcking after fixing typos\nunique_methods <- unique(data$sales_method)\nprint(unique_methods)\n\nunique_product_count <- unique(data$nb_sold)\n\n# Revenue has only 7% missing data and hence droppping NAs\ndata_clean <- data %>% filter(!is.na(revenue))\n\n# values should not exceed 40 and hence filtering\ndata_clean <- data_clean %>% \n\tfilter(!years_as_customer > 40)\n\n# site visits\nsummary(data_clean$nb_site_visits)\n\nunique_state <- unique(data_clean$state)\nprint(unique_state)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RColorBrewer)\n\npastel_colors <- brewer.pal(6, \"Pastel2\")\n\nggplot(data_clean, aes(x = as.factor(week), y = revenue, fill = sales_method)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = pastel_colors) +\n  labs(x = \"Week\", y = \"Revenue\", fill = \"Sales Method\") +\n  ggtitle(\"Revenue by Week and Sales Method\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Method comparison-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_clean, aes(y = revenue)) +\n  geom_boxplot() +\n  labs(y = \"Revenue\") +\n  ggtitle(\"Revenue Distribution\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Revenue distribution-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter high-revenue customers (above 200.00)\nhigh_rev_cust <- data_clean %>%\n  filter(revenue > 200.00)\n\n# Aggregate data by state\ndata_aggregated <- high_rev_cust %>%\n  group_by(state) %>%\n  summarise(total_revenue = sum(revenue, na.rm = TRUE)) %>%\n  ungroup()\n\n# Sort data by total_revenue in descending order\ndata_aggregated <- data_aggregated %>%\n  arrange(desc(total_revenue))\n\n# Reorder state factor levels based on total_revenue\ndata_aggregated$state <- factor(data_aggregated$state, levels = data_aggregated$state)\n\nggplot(data_aggregated, aes(x = \"\", y = state, fill = total_revenue)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"orange\", name = \"Total Revenue\") +\n  labs(x = \"State\", y = NULL, fill = \"Total Revenue\") +\n  ggtitle(\"Total Revenue by State for High Value Customers\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 6)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Location of high value customers-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}