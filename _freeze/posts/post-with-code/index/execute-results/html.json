{
  "hash": "caa360f476b92599f362889f9d0dd21a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Certification Exam\"\ndate: \"2024-06-23\"\ncategories: [R, PowerBI, analysis]\nimage: \"certificate.jpg\"\n---\n\n\n\nAs part of the certified data analyst exam by DataCamp, I completed a two-hour exam testing my R and SQL skills, followed by a four-hour practical exam where I analyzed sales data from a stationary shop.\n\nThe goal of the analysis was to determine the best-performing marketing method following the launch of new products. Additionally, I identified high-paying and loyal customers to prioritize them in the marketing strategy for future product launches. Here are some examples but the full report can be found [here](https://www.datacamp.com/datalab/w/efdedffd-1df1-4b55-be0e-4c7c6ed91eb7).\n\nAnalysis was conduct with following components:\n\n1.  Data Cleaning and Validation\n\n2.  Exploratory Analysis\n\n3.  Key Business Metric Identification\n\n4.  Recommendation\n\n5.  Presentation (12 min, video)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nsetwd(\"C:/Users/udwal/Documents/Studies_Viadrina/Becoming Data Fluent/Fluent2024/Bonus Assignment/Portfolio\")\n\n# Importing data\ndata <- read_csv(\"product_sales.csv\")\n\n#  Checking uneque customer IDs\nnum_unique_customers <- length(unique(data$customer_id))\n\n# Checking column unique categorical values \nunique_methods <- unique(data$sales_method)\n\n# fixing typos\ntypo_dict <- c(\n  \"em + call\" = \"Email + Call\",\n  \"email\" = \"Email\")\n\ndata <- data %>%\n  mutate(sales_method = coalesce(typo_dict[sales_method], sales_method))\n\n# Cehcking after fixing typos\nunique_methods <- unique(data$sales_method)\nprint(unique_methods)\n\nunique_product_count <- unique(data$nb_sold)\n\n# Revenue has only 7% missing data and hence droppping NAs\ndata_clean <- data %>% filter(!is.na(revenue))\n\n# values should not exceed 40 and hence filtering\ndata_clean <- data_clean %>% \n\tfilter(!years_as_customer > 40)\n\n# site visits\nsummary(data_clean$nb_site_visits)\n\nunique_state <- unique(data_clean$state)\nprint(unique_state)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RColorBrewer)\n\npastel_colors <- brewer.pal(6, \"Pastel2\")\n\nggplot(data_clean, aes(x = as.factor(week), y = revenue, fill = sales_method)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = pastel_colors) +\n  labs(x = \"Week\", y = \"Revenue\", fill = \"Sales Method\") +\n  ggtitle(\"Revenue by Week and Sales Method\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Method comparison-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_clean, aes(y = revenue)) +\n  geom_boxplot() +\n  labs(y = \"Revenue\") +\n  ggtitle(\"Revenue Distribution\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Revenue distribution-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter high-revenue customers (above 200.00)\nhigh_rev_cust <- data_clean %>%\n  filter(revenue > 200.00)\n\n# Aggregate data by state\ndata_aggregated <- high_rev_cust %>%\n  group_by(state) %>%\n  summarise(total_revenue = sum(revenue, na.rm = TRUE)) %>%\n  ungroup()\n\n# Sort data by total_revenue in descending order\ndata_aggregated <- data_aggregated %>%\n  arrange(desc(total_revenue))\n\n# Reorder state factor levels based on total_revenue\ndata_aggregated$state <- factor(data_aggregated$state, levels = data_aggregated$state)\n\nggplot(data_aggregated, aes(x = \"\", y = state, fill = total_revenue)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"orange\", name = \"Total Revenue\") +\n  labs(x = \"State\", y = NULL, fill = \"Total Revenue\") +\n  ggtitle(\"Total Revenue by State for High Value Customers\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 6)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Location of high value customers-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}